{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ../beamline_configuration.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non scaler data\n",
    "\n",
    "We can read more than just scalar data using Bluesky.  For handling\n",
    "non-scalar data (such as from imaging detectors or MCAs) we do not\n",
    "directly store the data in the databroker, instead we store _pointer_\n",
    "to where the data is and how to access it.\n",
    "\n",
    "Lets take a single frame of a low signal-to-noise detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RE(bps.mv(dot.exp, .005))\n",
    "RE(bps.mv(mtr_dotx, 0, mtr_doty, 0))\n",
    "\n",
    "uid, = RE(bp.count([dot, I], num=1))\n",
    "h_one = db[uid]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we look at this with `table`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_one.table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see uid strings in the column where we expect our image to be!  To ask\n",
    "data broker to fetch the image data from disk we can pass the optional kwarg `fill`\n",
    "to `table`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_one.table(fill=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_one.table(fill=True)['dot_img'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "but it is embedded in a Pandas data frame.  The `Header` has the\n",
    "=data= method which pulls out one column of the data set (and defaults to\n",
    "`fill=True`)\n",
    "\n",
    "The object returned by `h.data` is a =generator= which will lazily return\n",
    "one value at a time.  To grab just the first image we can use `next`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = next(h_one.data('dot_img'))\n",
    "fig, ax = plt.subplots()\n",
    "im_ = ax.imshow(im)\n",
    "fig.colorbar(im_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we know there is exactly 1 image we can unpack it like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im, = h_one.data('dot_img')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uid, = RE(bp.count([dot, I], num=5))\n",
    "h_few = db[uid]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there is more than one we can use `list`, `np.vstack`, or\n",
    "generalize unpacking to pull all of the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_list = list(h_few.data('dot_img'))\n",
    "im_stack = np.stack(h_few.data('dot_img'))\n",
    "im1, *rest = h_few.data('dot_img')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also iterate through all of them with a `for` loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j, im in enumerate(h_few.data('dot_img')):\n",
    "    print(f'frame {j} has max {im.max()}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This has the nice feature that there is only ever 1 frame in memory at a time.  For these 5 small images, this is not a huge issue, but this technique can allow you to process data significantly bigger than your available memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets take a bunch of images to improve the statistics!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "uid, = RE(bp.count([dot, I], num=150))\n",
    "h_lots = db[uid]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can again use =next= to peek at the first image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = next(h_lots.data('dot_img'))\n",
    "fig, ax = plt.subplots()\n",
    "im_ = ax.imshow(im)\n",
    "fig.colorbar(im_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then grab the whole stack, average them to one image and\n",
    "display the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "im_stack = np.stack(h_lots.data('dot_img'))\n",
    "\n",
    "vmin = im_stack.min()\n",
    "vmax = im_stack.max()\n",
    "\n",
    "im1 = ax1.imshow(im_stack[0], vmin=vmin, vmax=vmax)\n",
    "im2 = ax2.imshow(im_stack.mean(axis=0), vmin=vmin, vmax=vmax)\n",
    "\n",
    "ax1.set_title('1 frame')\n",
    "ax2.set_title('mean of stack')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`data` can pull out any column.  If you want to access both the beam\n",
    "current and the image you could do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = np.zeros(h_lots.descriptors[0]['data_keys']['dot_img']['shape'])\n",
    "j = 0\n",
    "for cur, im in zip(h_lots.data('I'), h_lots.data('dot_img')):\n",
    "    out += im / cur\n",
    "    j += 1\n",
    "\n",
    "out /= j\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, if you need to access more than one key, it may be better to\n",
    "use the =Event= documents directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "RE(bps.mv(dot.exp, 5))\n",
    "\n",
    "uid, = RE(bp.spiral_fermat([I, dot], mtr_dotx, mtr_doty, 0, 0, 75, 75, 3, 1))\n",
    "h_spiral = db[uid]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def tri_helper(df, ax, title):\n",
    "    ax.tricontour(df['x'], df['y'], df['c'], 10, linewidths=0.5, colors='k')\n",
    "    t = ax.tricontourf(df['x'], df['y'], df['c'], 10)\n",
    "    ax.set_title(title)\n",
    "    ax.set_aspect('equal')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ret = []\n",
    "for ev in h_spiral.events(fill=True):\n",
    "    data = ev['data']\n",
    "    im = data['dot_img']\n",
    "\n",
    "    ret.append({'x': data['motor_dotx'],\n",
    "                'y': data['motor_doty'],\n",
    "                'c': np.mean(im[im > 1000])})\n",
    "\n",
    "df = pd.DataFrame(ret)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ret = []\n",
    "for ev in h_spiral.events(fill=True):\n",
    "    data = ev['data']\n",
    "    im = data['dot_img']\n",
    "\n",
    "    ret.append({'x': data['motor_dotx'],\n",
    "                'y': data['motor_doty'],\n",
    "                'c': np.mean(im[im > 1000]) / data['I']})\n",
    "\n",
    "df_normed = pd.DataFrame(ret)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "tri_helper(df, ax1, 'un normalized')\n",
    "tri_helper(df_normed, ax2, 'normalized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0a0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 06 - Handling Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading metadata history from /home/tcaswell/.config/bluesky/bluesky_history.db\n"
     ]
    }
   ],
   "source": [
    "%run ../beamline_configuration.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Array data in Theory\n",
    "\n",
    "We can read more than just scalar data using Bluesky.  For handling\n",
    "non-scalar data (such as from imaging detectors or MCAs) we do not\n",
    "directly store the data in the databroker, instead we store _pointer_\n",
    "to where the data is and how to access it.  This design allows us to buffer the user from such mundane details as what the filename and format of the underlying data is.  \n",
    "This is also motivated in part by performance concerns both at the database level, you do not want to put gigabytes of binary data into a database, and at the collection level, we do not want to put Bluesky between detectors and disk. \n",
    "\n",
    "In short, these _pointers_ allow *DataBroker* to do the file I/O work of opening and extracting data from disk and returns to you numpy arrays.  For more [details about how this works](https://nsls-ii.github.io/databroker/assets.html) see the DataBroker documentation.\n",
    "\n",
    "\n",
    "## Array data in practice\n",
    "\n",
    "Lets take a single frame of a low signal-to-noise detector to see how this works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RE(bps.mv(spot.exp, .005))  # low exposure time so we will get significant noise\n",
    "RE(bps.mv(mtr_spotx, 0, mtr_spoty, 0))  # set position to dead center\n",
    "\n",
    "uid, = RE(bp.count([spot, I], num=1))\n",
    "h_one = db[uid]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we look at this with `table`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_one.table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see a uid string in the column where we expect our image to be!  Taking a look at the `'spot_img'`'s entry in the descriptor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_one.descriptors[0]['data_keys']['spot_img']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we see that the expeted shape is `(480, 640)` and `'external'` key indicates that these strings are keys to trade to the *DataBroker* for the actual data. To ask\n",
    "*DataBroker* to fetch the image data from disk we can pass the optional kwarg `fill`\n",
    "to `table`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_one.table(fill=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_one.table(fill=True)['spot_img'][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "but it is embedded in a Pandas data frame.  The `Header` has the\n",
    "``data`` method which pulls out one column of the stream (and defaults to\n",
    "`fill=True`).\n",
    "\n",
    "The object returned by `h.data` is a *generator* which will lazily return\n",
    "one value at a time.  To grab just the first image we can use `next`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = next(h_one.data('spot_img'))\n",
    "fig, ax = plt.subplots()\n",
    "im_ = ax.imshow(im)\n",
    "fig.colorbar(im_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have already been working with *generator* functions as under-the-hood the built in  *BlueSky* plans are all generators.  For more details on generators see [the BlueSky appendix](https://nsls-ii.github.io/bluesky/appendix.html) or google [\"James Powell generators youtube\"](https://www.google.com/search?q=james+powell+generators+youtube).\n",
    "\n",
    "If we know there is exactly 1 image we can unpack it like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im, = h_one.data('spot_img')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To play with generators a bit more, lets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uid, = RE(bp.count([spot, I], num=5))\n",
    "h_few = db[uid]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there is more than one we can use `list`, `np.vstack`, or\n",
    "generalize unpacking to pull all of the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_list = list(h_few.data('spot_img'))\n",
    "im_stack = np.stack(h_few.data('spot_img'))\n",
    "im1, *rest = h_few.data('spot_img')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also iterate through all of them with a `for` loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j, im in enumerate(h_few.data('spot_img')):\n",
    "    print(f'frame {j} has max {im.max()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This has the nice feature that there is only ever 1 frame in memory at a time.  For these 5 small images, this is not a huge issue, but this technique can allow you to process data significantly bigger than your available memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intermission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take a few minutes to play the the 4 ways to get all of the images out of the generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summing Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets take a bunch of images to improve the statistics!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "uid, = RE(bp.count([spot, I], num=150))\n",
    "h_lots = db[uid]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can again use =next= to peek at the first image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = next(h_lots.data('spot_img'))\n",
    "fig, ax = plt.subplots()\n",
    "im_ = ax.imshow(im)\n",
    "fig.colorbar(im_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then grab the whole stack, average them to one image and\n",
    "display the result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "im_stack = np.stack(h_lots.data('spot_img'))\n",
    "\n",
    "vmin = im_stack.min()\n",
    "vmax = im_stack.max()\n",
    "\n",
    "im1 = ax1.imshow(im_stack[0], vmin=vmin, vmax=vmax)\n",
    "im2 = ax2.imshow(im_stack.mean(axis=0), vmin=vmin, vmax=vmax)\n",
    "\n",
    "ax1.set_title('1 frame')\n",
    "ax2.set_title('mean of stack')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`data` can pull out any column.  If you want to access both the beam\n",
    "current and the image you could do:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = np.zeros(h_lots.descriptors[0]['data_keys']['spot_img']['shape'])\n",
    "j = 0\n",
    "for cur, im in zip(h_lots.data('I'), h_lots.data('spot_img')):\n",
    "    out += im / cur\n",
    "    j += 1\n",
    "\n",
    "out /= j\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, if you need to access more than one key, it may be better to\n",
    "use the *Event* documents directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "RE(bps.mv(spot.exp, 5))\n",
    "\n",
    "uid, = RE(bp.spiral_fermat([I, spot], mtr_spotx, mtr_spoty, 0, 0, 75, 75, 3, 1))\n",
    "h_spiral = db[uid]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def tri_helper(df, ax, title):\n",
    "    ax.tricontour(df['x'], df['y'], df['c'], 10, linewidths=0.5, colors='k')\n",
    "    t = ax.tricontourf(df['x'], df['y'], df['c'], 10)\n",
    "    ax.set_title(title)\n",
    "    ax.set_aspect('equal')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ret = []\n",
    "for ev in h_spiral.events(fill=True):\n",
    "    data = ev['data']\n",
    "    im = data['spot_img']\n",
    "\n",
    "    ret.append({'x': data['motor_spotx'],\n",
    "                'y': data['motor_spoty'],\n",
    "                'c': np.mean(im[im > 1000])})\n",
    "\n",
    "df = pd.DataFrame(ret)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ret = []\n",
    "for ev in h_spiral.events(fill=True):\n",
    "    data = ev['data']\n",
    "    im = data['spot_img']\n",
    "\n",
    "    ret.append({'x': data['motor_spotx'],\n",
    "                'y': data['motor_spoty'],\n",
    "                'c': np.mean(im[im > 1000]) / data['I']})\n",
    "\n",
    "df_normed = pd.DataFrame(ret)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "tri_helper(df, ax1, 'un normalized')\n",
    "tri_helper(df_normed, ax2, 'normalized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
